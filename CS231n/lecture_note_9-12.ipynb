{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture Note 9 Understanding and Visualizing Convolutional Neural Networks\n",
    "\n",
    "### filters visualization \n",
    "- visualize filters (weights)\n",
    "\n",
    "### last layer\n",
    "- using Nearest Neighbors on the last layer of  many images\n",
    "- t-SNE, Dimensionality Reduction, subject the final layer of image to 2 dims\n",
    "\n",
    "### visualizing activations\n",
    "\n",
    "### Occlusion experiments\n",
    "- Mask part of the image before feeding to CNN, draw heatmap of probability at each mask location\n",
    "\n",
    "### saliency maps\n",
    "- Compute gradient of (unnormalized) class score with respect to image pixels, take absolute value and max over RGB channels\n",
    "- one way to segment\n",
    "\n",
    "### Intermediate Features via (guided) backprop\n",
    "- Compute gradient of neuron value with respect to image pixels\n",
    "- guided relu back prop, kill negative gradient, or influence\n",
    "\n",
    "### Visualizing CNN features: Gradient Ascent\n",
    "- update the image (all zeros at the begining) to maximize the neuron ouput\n",
    "\n",
    "### fooling ConvNets\n",
    "- pose optimization over input image to maximize any class score\n",
    "- above strategy is effective at changing the prediction but totally not on original data, the image changes little\n",
    "- result of linear classifier can be changed easily even if the overall data changes little\n",
    "\n",
    "### deepdream\n",
    "- Choose an image and a layer in a CNN; repeat:\n",
    "    1. Forward: compute activations at chosen layer\n",
    "    2. Set gradient of chosen layer equal to its activation\n",
    "    3. Backward: Compute gradient on image\n",
    "    4. Update image\n",
    "\n",
    "### feature inversion\n",
    "- Given a CNN feature vector for an image, find a new image that:\n",
    "    - Matches the given feature vector\n",
    "    - “looks natural” (image prior regularization)\n",
    "\n",
    "### Texture Synthesis\n",
    "- Nearest Neighbor copying\n",
    "- Gram Matrix(how to compute? in ppt P54-57)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture Note 10 RNN\n",
    "\n",
    "- flexibility: one | many to one | many \n",
    "- RNN\n",
    "    - timestep\n",
    "    - same computational graph every timestep\n",
    "    - every cell take two inputs, last timestep output & last layer output\n",
    "    - how everything computed, ppt p22\n",
    "    - important to clarify how to back prop through the cell \n",
    "    - basically you can feed in any text with order RNN, tex, code\n",
    " \n",
    "- Image Captioning\n",
    "    - take the feature ouput of ConvNet as input as the input of hidden layer in the first timestep  only\n",
    "    - take the output of this time step (a word) as the input of next time step\n",
    "    - there wil be an token \\<END\\> indicating the end of caption\n",
    "- training a model vanilla\n",
    "    - iterate over inputs, forward pass\n",
    "    - inverselty iterate to back prop, accmulate gradients!!\n",
    "    - iteration length is limited, things are done in epoch - sequence length\n",
    "   \n",
    "- image captioning with attention\n",
    "    - generate distribution over L locations along with word at the same time\n",
    "    - turn locations into weighted features \n",
    "    - take weighted features & word as the input of next timestep\n",
    "    \n",
    "- visual question answearing: RNN with attention, see 17 sildes p88\n",
    "- lstm, see the sildes for detailed formula\n",
    "    - similiar to ResNet\n",
    "    - hidden cell have to variables, h & c \n",
    "    - additive interactions improve gradient flow, addition equally distribute gradient\n",
    "    \n",
    "- gradient flow in RNN\n",
    "     - vanilla type may result in gradients explode or vanish due to iteration in the one epoch\n",
    "     - use gradient clipping to control explosion\n",
    "     - use lstm to control vanishing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture Note 11 ConvNets in Pratice\n",
    "\n",
    "## Data augmentation\n",
    "1. Horizontal flips\n",
    "2. Random crops/scales, different between training & testing see slides 19\n",
    "3. color jitter, use pca, see slides 21\n",
    "4. get creative, translation, rotation\n",
    "\n",
    "- data augmentatin similiar to dropout\n",
    "- useful for small datasets\n",
    "\n",
    "## Transfer learning(less data)\n",
    "- more data more layers, vice versa\n",
    "- use frozen part networks as feature extractor, data tranformer(forward pass once to produce new form of data)\n",
    "- fine tune method\n",
    "    1. learning rate tip, see slides p30\n",
    "    2. stage fine tune which is tune last layer first, then tune last few layers, because the gradients is too large at the last layer(?)\n",
    "- dataset size v.s. dataset difference matrix, see slides p34\n",
    "\n",
    "## All about convolutions\n",
    "\n",
    "### stacking\n",
    "- stacking make one neuron can see more areas\n",
    "- small filters, more nonlinearity, less paras, less computation\n",
    "- bottleneck sandwich, more nonlinearity, less params, less compute\n",
    "\n",
    "### computation\n",
    "- im2col, turn conv into matrix, see slides\n",
    "- Convolution Theorem, Fast Fourier Transform, slow with small filters\n",
    "- Strassen's Algorithm, real fast?\n",
    "\n",
    "## Implementation Details\n",
    "\n",
    "### bottleneck\n",
    "- cpu-gpu communication\n",
    "    - dataprefetch + augment \n",
    "    - turn pics into one giant raw byte stream because pics may store in different places\n",
    "\n",
    "### floating point precision\n",
    "- 32bit to save memory & speed up computing\n",
    "- 16bit faster\n",
    "- 10bit forward & 12bit backward\n",
    "- 1 bit ?\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture Note 12 Software Packages \n",
    "\n",
    "## caffe\n",
    "- no need to write code\n",
    "- have things done in pro file, just assign everything, the input data, the layers, the parameters, the archtecture, \n",
    "- datastructure\n",
    "    - Blob: Stores data and derivatives\n",
    "    - Layer: Transforms bottom blobs to top blobs (the same as the layer coded in assignments)\n",
    "    - Net: Many layers; computes gradients via forward / backward\n",
    "    - Solver: Uses gradients to update weights\n",
    "\n",
    "## Torch\n",
    "- modules in lua, like packages in python\n",
    "- modules are easy to use, there are tensors, nn (layers stack), etc\n",
    "\n",
    "## Tensorflow\n",
    "- computational graph is key\n",
    "- code the symbolic computation procedure, then run the real computation\n",
    "- auto derive gradient\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
